# pytorch-learning
A collection of practice notebooks for mastering PyTorch, covering activation functions, softmax, shallow neural networks, autograd, and linear regression.
# PyTorch Practice Projects

This repository contains a collection of Jupyter notebooks created to strengthen my understanding of PyTorch and core deep learning concepts. The notebooks cover a variety of topics including activation functions, shallow neural networks, regression, softmax, and autograd.

## üìÅ Contents

| Notebook | Description |
|----------|-------------|
| `Activation_Functions.ipynb` | Visual exploration of ReLU, Sigmoid, and Tanh functions |
| `Shallow_Neural_Networks.ipynb` | Implementation and training of basic neural networks from scratch |
| `Softmax_practice.ipynb` | Manual implementation of the softmax function and its behavior |
| `Softmax_in_Pytorch.ipynb` | Use of PyTorch‚Äôs built-in softmax layer for classification tasks |
| `Regression_using_Pytorch.ipynb` | Simple linear regression using PyTorch |
| `Multiple_Linear_Regression_Prediction.ipynb` | Linear regression with multiple input features |
| `customautograd.ipynb` | Example of building a custom autograd function for backpropagation |
| `PyTorch_Practice.ipynb` | General model training practice using PyTorch |

## üöÄ Getting Started

To run these notebooks on your local machine, follow the steps below.

### Option 1: Manual Installation

Install the required Python libraries:

```bash
pip install torch matplotlib notebook
